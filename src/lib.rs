use std::{
    hash::Hasher,
    io::{self, Read, Write},
};

use thiserror::Error;

// this is the largest prime number < 2^64. As we will probably never encounter
// a Bloom filter with a number of bits > m (if yes sorry to you people from,
// the future, I envy your available RAM though) we can use the pseudorandom
// sequence generated by repeatedly multiplying the initial hash value h
// with g and taking the modulo over m to generate a sequence of hash values
// that has a uniform distribution.
const M: u64 = 18446744073709551557;

// this is our multiplier. It has a very large primitive root
// so that it will not repeat a given cycle for any practically meaningful
// value of k.
const G: u64 = 18446744073709550147;

pub struct Fingerprint {
    hn: u64,
    m: u64,
    i: u64,
    size: u64,
}

impl Fingerprint {
    pub fn with_size<H: std::hash::Hasher + Default>(data: &[u8], modulo: u64, size: u64) -> Self {
        let mut hasher: H = H::default();
        hasher.write(data.as_ref());
        Self {
            hn: hasher.finish(),
            m: modulo,
            i: 0,
            size,
        }
    }
}

impl Iterator for Fingerprint {
    type Item = u64;
    #[inline(always)]
    fn next(&mut self) -> Option<Self::Item> {
        if self.i < self.size {
            self.hn = self.hn.wrapping_mul(G);
            self.hn %= M;
            self.i += 1;
            return Some(self.hn % self.m);
        }
        None
    }
}

fn read_le_u64<R: Read>(r: &mut R) -> Result<u64, io::Error> {
    let mut bytes = [0u8; 8];
    r.read_exact(bytes.as_mut_slice())?;
    Ok(u64::from_le_bytes(bytes))
}

#[derive(Debug, Error)]
pub enum Error {
    #[error("{0}")]
    IoError(#[from] io::Error),
    #[error("invalid version {0}")]
    InvalidVersion(u64),
}

#[allow(non_snake_case)]
#[derive(Debug, Default)]
pub struct BloomFilter {
    v: Vec<u64>,
    n: u64,
    p: f64,
    k: u64,
    m: u64,
    pub N: u64,
    pub M: u64,
    pub data: Vec<u8>,
}

impl BloomFilter {
    #[inline(always)]
    fn fingerprint<S: AsRef<[u8]>>(&self, value: S) -> Fingerprint {
        Fingerprint::with_size::<Fnv1Hasher>(value.as_ref(), self.m, self.k)
    }

    pub fn with_capacity(cap: u64, proba: f64) -> Self {
        // size in bits, computed from the capacity we want and the probability
        let bit_size = f64::abs(f64::ceil(
            (cap as f64) * f64::log2(proba) / f64::log2(2.0).powf(2.0),
        ));

        // size in bytes
        let u64_size = f64::ceil(bit_size / 64.0) as usize;

        Self {
            v: vec![0; u64_size],
            n: cap,
            p: proba,
            k: f64::ceil(f64::log2(2.0) * bit_size / (cap as f64)) as u64,
            m: bit_size as u64,
            N: 0,
            M: u64_size as u64,
            data: vec![],
        }
    }

    pub fn from_reader<R: Read>(mut r: R) -> Result<Self, Error> {
        let flags = read_le_u64(&mut r)?;
        let mut b = Self::default();

        let version = flags & 0xff;

        if version != 1 {
            return Err(Error::InvalidVersion(version));
        }

        b.n = read_le_u64(&mut r)?;
        b.p = (read_le_u64(&mut r)?) as f64;
        b.k = read_le_u64(&mut r)?;
        b.m = read_le_u64(&mut r)?;
        b.N = read_le_u64(&mut r)?;

        // initializing bitset
        b.M = f64::ceil((b.m as f64) / 64.0) as u64;
        b.v = vec![0; b.M as usize];

        // reading the bloom filter
        for i in b.v.iter_mut() {
            *i = read_le_u64(&mut r)?;
        }

        // reading data
        b.data = std::io::read_to_string(r)?.as_bytes().to_vec();

        Ok(b)
    }

    pub fn write<W: Write>(&self, w: &mut W) -> Result<(), Error> {
        w.write_all(&1u64.to_le_bytes())?;
        w.write_all(&self.n.to_le_bytes())?;
        w.write_all(&self.p.to_le_bytes())?;
        w.write_all(&self.k.to_le_bytes())?;
        w.write_all(&self.m.to_le_bytes())?;
        w.write_all(&self.N.to_le_bytes())?;

        for i in self.v.iter() {
            w.write_all(&i.to_le_bytes())?;
        }

        w.write_all(&self.data)?;
        Ok(())
    }

    #[inline(always)]
    /// get the nth bit value
    fn get_nth_bit(&self, index: u64) -> bool {
        let block = index / 64;
        let bit = index % 64;
        self.v[block as usize] & (1u64 << bit) == (1u64 << bit)
    }

    #[inline(always)]
    /// set the nth bit and returns old value
    fn set_nth_bit(&mut self, index: u64) -> bool {
        let block = index / 64;
        let bit = index % 64;
        // this is the old bit value
        let old = self.v[block as usize] & (1u64 << bit) == (1u64 << bit);
        self.v[block as usize] |= 1u64 << bit;
        old
    }

    pub fn bits(&self) -> Vec<bool> {
        (0..self.m)
            .map(|i| self.get_nth_bit(i))
            .collect::<Vec<bool>>()
    }

    #[inline(always)]
    pub fn insert<S: AsRef<[u8]>>(&mut self, value: S) {
        let mut new = false;
        self.fingerprint(value).for_each(|index| {
            // if old value was 0 we mark it as a new entry
            if !self.set_nth_bit(index) {
                new = true
            }
            debug_assert!(self.get_nth_bit(index))
        });
        if new {
            self.N += 1;
        }
    }

    #[inline(always)]
    pub fn clear(&mut self) {
        self.v.iter_mut().for_each(|bucket| *bucket = 0);
        self.N = 0;
    }

    #[inline(always)]
    pub fn contains<S: AsRef<[u8]>>(&self, value: S) -> bool {
        for index in self.fingerprint(value) {
            if !self.get_nth_bit(index) {
                return false;
            }
        }
        true
    }

    #[inline(always)]
    /// returns an estimate of the number of element in the filter
    /// the exact number of element cannot be known as there might
    /// be collisions
    pub fn count_estimate(&self) -> u64 {
        self.N
    }

    pub fn size_in_bytes(&self) -> usize {
        self.M as usize * core::mem::size_of::<u64>()
    }
}

const FNV_OFFSET: u64 = 14695981039346656037;
const FNV_PRIME: u64 = 1099511628211;

#[derive(Debug)]
pub struct Fnv1Hasher {
    sum: u64,
}

impl Default for Fnv1Hasher {
    fn default() -> Self {
        Self { sum: FNV_OFFSET }
    }
}

impl Hasher for Fnv1Hasher {
    #[inline(always)]
    fn finish(&self) -> u64 {
        self.sum
    }

    #[inline(always)]
    fn write(&mut self, bytes: &[u8]) {
        bytes.iter().for_each(|b| {
            self.sum = self.sum.wrapping_mul(FNV_PRIME);
            self.sum ^= *b as u64;
        })
    }
}

impl Fnv1Hasher {
    // ToDo move this to a generic taking a Hasher as param
    pub fn digest<S: AsRef<[u8]>>(s: S) -> u64 {
        let mut h = Self::default();
        h.write(s.as_ref());
        h.finish()
    }
}

// bloom![cap, prob, {values...}]
#[macro_export]
macro_rules! bloom {
        ($cap:literal, $proba:literal) => {
            $crate::BloomFilter::with_capacity($cap, $proba)
        };
        ($cap:literal, $proba:literal, [$($values:literal),*]) => {
            {
                let mut b=bloom!($cap, $proba);
                $(b.insert($values);)*
                b
            }
        };
    }

#[cfg(test)]
mod tests {
    use std::io::{self};

    use super::*;

    #[test]
    // this test checks that FnvHasher returns the exact same value as the
    // go library (used in DCSOÂ implementation)
    fn test_fnv() {
        assert_eq!(Fnv1Hasher::digest("Hello, World!"), 8889723880822884486);
        assert_eq!(
            Fnv1Hasher::digest("Let's rustify all this"),
            13581150826273240441
        );
    }

    #[test]
    fn test_fnv_update() {
        let mut hasher = Fnv1Hasher::default();
        hasher.write("Hello, ".as_bytes());
        hasher.write("World!".as_bytes());
        assert_eq!(hasher.finish(), 8889723880822884486)
    }

    #[test]
    fn test_bloom() {
        let mut b = BloomFilter::with_capacity(100000, 0.001);
        assert!(!b.contains("value"));
        b.insert("value");
        assert!(b.contains("value"));
        assert_eq!(b.N, 1);
        assert!(!b.contains("unknown"));
    }

    #[test]
    fn test_macro() {
        let b = bloom!(1000, 0.0001, ["hello", "world"]);
        assert!(b.contains("hello"));
        assert!(b.contains("world"));
    }

    #[test]
    fn test_serialization() {
        let b = bloom!(1000, 0.0001, ["deserialization", "test"]);
        let mut cursor = io::Cursor::new(vec![]);
        b.write(&mut cursor).unwrap();
        cursor.set_position(0);
        // deserializing the stuff out
        let b = BloomFilter::from_reader(cursor).unwrap();
        assert!(b.contains("deserialization"));
        assert!(b.contains("test"));
        assert!(!b.contains("hello"));
        assert!(!b.contains("world"));
    }

    #[test]
    fn test_deserialization() {
        // this test file has been generated with Go bloom cli
        let data = include_bytes!("./data/test.bloom");
        let b = BloomFilter::from_reader(io::BufReader::new(io::Cursor::new(data))).unwrap();
        assert!(b.contains("hello"));
        assert!(b.contains("world"));
        assert!(!b.contains("hello world"));
    }
}
