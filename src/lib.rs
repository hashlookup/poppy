// this is the largest prime number < 2^64. As we will probably never encounter
// a Bloom filter with a number of bits > m (if yes sorry to you people from,
// the future, I envy your available RAM though) we can use the pseudorandom
// sequence generated by repeatedly multiplying the initial hash value h
// with g and taking the modulo over m to generate a sequence of hash values
// that has a uniform distribution.
const M: u64 = 18446744073709551557;

// this is our multiplier. It has a very large primitive root
// so that it will not repeat a given cycle for any practically meaningful
// value of k.
const G: u64 = 18446744073709550147;

pub struct Fingerprint {
    hn: u64,
    m: u64,
    i: u64,
    size: u64,
}

impl Fingerprint {
    pub fn with_size<S: AsRef<[u8]>>(data: S, modulo: u64, size: u64) -> Self {
        Self {
            hn: Fnv1Hasher::digest(data),
            m: modulo,
            i: 0,
            size,
        }
    }
}

impl Iterator for Fingerprint {
    type Item = u64;
    #[inline(always)]
    fn next(&mut self) -> Option<Self::Item> {
        if self.i < self.size {
            self.hn = self.hn.wrapping_mul(G);
            self.hn %= M;
            self.i += 1;
            return Some(self.hn % self.m);
        }
        None
    }
}

#[derive(Debug, Default)]
pub struct BloomFilter {
    v: Vec<u64>,
    n: u64,
    p: f64,
    k: u64,
    m: u64,
    pub N: u64,
    pub M: u64,
    pub data: Vec<u8>,
}

impl BloomFilter {
    #[inline(always)]
    fn fingerprint<S: AsRef<[u8]>>(&self, value: S) -> Fingerprint {
        Fingerprint::with_size(value, self.m, self.k)
    }

    pub fn with_capacity(cap: u64, proba: f64) -> Self {
        // size in bits, computed from the capacity we want and the probability
        let bit_size = f64::abs(f64::ceil(
            (cap as f64) * f64::log2(proba) / f64::log2(2.0).powf(2.0),
        ));

        // size in bytes
        let byte_size = f64::ceil(bit_size / 64.0) as usize;

        Self {
            v: vec![0; byte_size],
            n: cap,
            p: proba,
            k: f64::ceil(f64::log2(2.0) * bit_size / (cap as f64)) as u64,
            m: bit_size as u64,
            N: 0,
            M: byte_size as u64,
            data: vec![],
        }
    }

    #[inline(always)]
    /// get the nth bit value
    fn get_nth_bit(&self, index: u64) -> bool {
        let block = index / 64;
        let bit = index % 64;
        self.v[block as usize] & (1u64 << bit) == (1u64 << bit)
    }

    #[inline(always)]
    /// set the nth bit and returns old value
    fn set_nth_bit(&mut self, index: u64) -> bool {
        let block = index / 64;
        let bit = index % 64;
        // this is the old bit value
        let old = self.v[block as usize] & (1u64 << bit) == (1u64 << bit);
        self.v[block as usize] |= 1u64 << bit;
        old
    }

    #[inline(always)]
    pub fn insert<S: AsRef<[u8]>>(&mut self, value: S) {
        let mut new = false;
        self.fingerprint(value).for_each(|index| {
            // if old value was 0 we mark it as a new entry
            if !self.set_nth_bit(index) {
                new = true
            }
            debug_assert!(self.get_nth_bit(index))
        });
        if new {
            self.N += 1;
        }
    }

    #[inline(always)]
    pub fn clear(&mut self) {
        self.v.iter_mut().for_each(|bucket| *bucket = 0);
        self.N = 0;
    }

    #[inline(always)]
    pub fn contains<S: AsRef<[u8]>>(&self, value: S) -> bool {
        for index in self.fingerprint(value) {
            if !self.get_nth_bit(index) {
                return false;
            }
        }
        true
    }

    #[inline(always)]
    /// returns an estimate of the number of element in the filter
    /// the exact number of element cannot be known as there might
    /// be collisions
    pub fn count_estimate(&self) -> u64 {
        self.N
    }
}

const FNV_OFFSET: u64 = 14695981039346656037;
const FNV_PRIME: u64 = 1099511628211;

pub trait Hasher {
    type Output;
    fn new() -> Self;

    fn update<S: AsRef<[u8]>>(&mut self, s: S);
    fn sum(&self) -> Self::Output;

    #[inline(always)]
    fn digest<S: AsRef<[u8]>>(s: S) -> Self::Output
    where
        Self: Sized,
    {
        let mut h = Self::new();
        h.update(s);
        h.sum()
    }
}

#[derive(Debug, Default)]
pub struct Fnv1Hasher {
    sum: u64,
}

impl Hasher for Fnv1Hasher {
    type Output = u64;
    fn new() -> Self {
        Self { sum: FNV_OFFSET }
    }

    #[inline(always)]
    fn update<S: AsRef<[u8]>>(&mut self, s: S) {
        s.as_ref().iter().for_each(|b| {
            self.sum = self.sum.wrapping_mul(FNV_PRIME);
            self.sum ^= *b as u64;
        })
    }

    #[inline(always)]
    fn sum(&self) -> u64 {
        self.sum
    }
}

#[cfg(test)]
mod tests {
    use std::{
        io::{self, BufRead},
        time::Duration,
    };

    use rand::Rng;

    use super::*;

    #[test]
    // this test checks that FnvHasher returns the exact same value as the
    // go library (used in DCSOÂ implementation)
    fn test_fnv() {
        assert_eq!(Fnv1Hasher::digest("Hello, World!"), 8889723880822884486);
        assert_eq!(
            Fnv1Hasher::digest("Let's rustify all this"),
            13581150826273240441
        );
    }

    #[test]
    fn test_fnv_update() {
        let mut hasher = Fnv1Hasher::new();
        hasher.update("Hello, ");
        hasher.update("World!");
        assert_eq!(hasher.sum(), 8889723880822884486)
    }

    #[test]
    fn test_bloom() {
        let mut b = BloomFilter::with_capacity(100000, 0.001);
        assert!(!b.contains("value"));
        b.insert("value");
        assert!(b.contains("value"));
        assert_eq!(b.N, 1);
        assert!(!b.contains("unknown"));
    }

    fn time_it<F: FnMut()>(mut f: F) -> Duration {
        let start_time = std::time::Instant::now();
        f();
        let end_time = std::time::Instant::now();
        end_time - start_time
    }

    #[test]
    fn benchmark_bloom() {
        let mut rng = rand::thread_rng();
        let data = include_bytes!("./data/all-hashes/42.txt");
        let count = include_str!("./data/all-hashes/42.count")
            .parse::<u64>()
            .unwrap();
        let collision_rate = 0.001;
        let mut b = BloomFilter::with_capacity(count, 0.001);
        let reader = io::BufReader::new(io::Cursor::new(data));
        let lines = reader.lines().flatten().collect::<Vec<String>>();

        let insert_dur = time_it(|| lines.iter().for_each(|l| b.insert(l)));

        let mb_size = data.len() as f64 / 1_048_576.0;

        eprintln!("data: {} entries -> {:.1} MB", count, mb_size);

        eprintln!("\nInsertion performance:");
        eprintln!("\tinsert duration: {:?}", insert_dur);
        eprintln!(
            "\tinsertion speed: {:.1} entries/s -> {:.1} MB/s",
            count as f64 / insert_dur.as_secs_f64(),
            mb_size / insert_dur.as_secs_f64()
        );

        eprintln!("\nQuery performance:");
        for mut_prob in (0..=100).step_by(10) {
            let mut tmp = lines.clone();
            let mutated_lines = tmp
                .iter_mut()
                .map(|e| {
                    if rng.gen_range(0..=100) < mut_prob {
                        unsafe { e.as_bytes_mut() }
                            .iter_mut()
                            .for_each(|b| *b ^= 42);
                    }
                    e.clone()
                })
                .collect::<Vec<String>>();

            let query_dur = time_it(|| {
                mutated_lines.iter().for_each(|l| {
                    b.contains(l);
                })
            });

            eprintln!("\t% of query not in filter: {}%", mut_prob);
            eprintln!("\tquery duration: {:?}", query_dur);
            eprintln!(
                "\tquery speed: {:.1} entries/s -> {:.1} MB/s",
                count as f64 / query_dur.as_secs_f64(),
                mb_size / query_dur.as_secs_f64()
            );
            eprintln!();
        }

        eprintln!("\nCollision information:");
        eprintln!("\texpected collision rate: {}", collision_rate);
        eprintln!(
            "\treal collision rate: {:.5}%",
            1.0 - (b.count_estimate() as f64) / count as f64
        );
    }
}
